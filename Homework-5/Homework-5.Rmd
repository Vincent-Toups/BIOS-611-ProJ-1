---
title: "Homework 5"
author: "Matt Johnson"
date: "10/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gbm)
library(cluster)
library(ggfortify)
```

Q1
==

#### Read in data
```{r, message=F}
DF <- read_csv("https://raw.githubusercontent.com/Vincent-Toups/bios611-project1/master/source_data/datasets_26073_33239_weight-height.csv") 
write.csv(DF, "Data.csv")
```

#### Split up data
```{r}
DF$Gender = ifelse(DF$Gender == "Male", 1, 0) #Male is 1, female is 0

set.seed <- 18 #this is my lucky number 
spec = c(train = .6, test = .2, validate = .2)
DF1 = sample(cut(
  seq(nrow(DF)), 
  nrow(DF)*cumsum(c(0,spec)),
  labels = names(spec)
))

DF.Split = split(DF, DF1)
```

#### GBM
```{r, message=F}
gbm1 <- gbm(Gender ~ Height + Weight, data = DF.Split$train, distribution = "bernoulli")

DF.Split$validate$gbm1.probs <- predict(gbm1, newdata = DF.Split$validate, type = "response")
DF.Split$validate <- DF.Split$validate %>% 
  mutate(gbm1_pred = 1*(gbm1.probs > .5) + 0) %>% 
  mutate(accurate.gbm1 = 1*(gbm1_pred == Gender))
sum(DF.Split$validate$accurate.gbm1)/nrow(DF.Split$validate)
```

The Accuracy of the GBM model is about .9 on the validation set. This is much much better than the previous gbm that had an accuracy around .5

Q2
==

#### Read in data
```{r, message = F}
DF2 <- read_csv("https://raw.githubusercontent.com/Vincent-Toups/bios611-project1/master/source_data/datasets_38396_60978_charcters_stats.csv")
```

#### Q2-1
```{r}
summary(DF2) #nothing seems to out of the ordinary right here, lets make a couple plots

DF2 %>% 
  ggplot(aes(x = Alignment)) +
  geom_bar() #there are a lot of goods and not too many neutrals. Also seems to be a couple NAs, before modeling we should remove the NAs

DF2 <- na.omit(DF2)

#lets take a look at how many nuetrals there are
nrow(DF2 %>% filter(Alignment == "neutral"))
#since there are only 11 neutrals and we are mostly concerned with good vs bad lets just take these neutral people out

DF2.no.neut <- DF2 %>% 
  filter(Alignment != "neutral")

#lets check for some outliers here too
DF2.no.neut %>% 
  ggplot(aes(x = Intelligence)) +
  geom_bar(aes(color = Alignment), position = "dodge") #nothing really irregular here, seems like bad people are a bit more inteligent though which is interesting
#checked similar plots with all other qualities and did not find anything too out of the ordinary
```
I guess just taking out the 11 neutrals is all I am going to do in this section. This seems reasonable becasue there are not many of them and a person identified as "neutral" is not very interesting for the analysis. 

#### Q2-2
```{r}
pca <- prcomp(DF2.no.neut[, -c(1, 2)])
summary(pca) #we would just need the primary principle component since it accounts for 95% of the variance
round(pca$rot[,1],2) #how the 1st principle component is made up...seems to be mostly made of the total column
```

#### Q2-3
Since the columns we are interested in, the numerical ones exept total, are already on the same scale from 0-100 we should not need to normalize anything here. We could normalize everything if we wanted to include the total column, but we see above that we should probably not include this column.

#### Q2-4
```{r, echo=F}
Total.Test = rowSums(DF2.no.neut[, -c(1, 2, 9)])
DF2.no.neut$Total == Total.Test #seems like this is true
```
Yes it seems that the 'total' column is the total of the numeric columns

#### Q2-5
I don't think we should be using the 'total' column in the pca since it is made up of the other columns. You can see from the code in section Q2-3 that the primary component is mostly made up of the total column.

#### Q2-6
```{r}
autoplot(pca)
```
Seems like a random distribution to me, I wouldn't say there are any insights to be made from this plot. 

Q3
==
```{r}
DF.TSNE <- read.csv("TSNE.csv")
DF.TSNE %>% 
  ggplot(aes(x = X1, y = X2)) +
  geom_point(aes(color = cluster))
```

Done in Homework-5.ipynb

Insights, seems like there might be two groups, we should do a pca to really check. There is a bit of overlap, but it looks like there could be two groups with some outliers (Small men, big women).

Q4
==
Done in Home-work-5.ipynb

